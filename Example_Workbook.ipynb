{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import cPickle as pickle\n",
    "from datetime import datetime\n",
    "import fnmatch\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2TkAgg\n",
    "from matplotlib import colors\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.gridspec as gridspec\n",
    "from multiprocessing import Pool,cpu_count\n",
    "from accelerate import cuda\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold='nan')\n",
    "import os\n",
    "import pyfits\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "import sys\n",
    "if sys.version_info[0] < 3:\n",
    "    import Tkinter as Tk\n",
    "else:\n",
    "    import tkinter as Tk\n",
    "    \n",
    "from tkFileDialog import askopenfilename,askdirectory,asksaveasfile\n",
    "\n",
    "import keplerml\n",
    "import km_outliers\n",
    "import db_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filelist = 'filelist.txt'\n",
    "fitsDir = 'data/Training_set_lightcurves'\n",
    "of = 'out.csv'\n",
    "keplerml.features_from_filelist(filelist,fitsDir,of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "============ Start ============\n",
    "\"\"\"\n",
    "\n",
    "# User defined\n",
    "featCSV = \"out.csv\"\n",
    "fitsDir = \"data/Training_set_lightcurves\"\n",
    "\n",
    "class feature_importer(object):\n",
    "    def __init__(self,feats,fitsDir):\n",
    "        self.data = pd.read_csv(feats,index_col=0)\n",
    "        self.fitsDir = fitsDir\n",
    "        self.files = self.data.index\n",
    "        # Initializing the data and files samples with the first 1000 entries.\n",
    "        self.dataSample = self.data.iloc[:1000]\n",
    "        self.filesSample = self.files[:1000]\n",
    "        self.lcs = self.poolRKC(self.filesSample)\n",
    "        \n",
    "    def poolRKC(self,files):\n",
    "        numcpus = cpu_count()\n",
    "        fwp = self.fitsDir+\"/\"+self.filesSample\n",
    "        p = Pool(numcpus)\n",
    "        lcs = p.map(keplerml.read_kepler_curve,fwp)\n",
    "        p.close()\n",
    "        p.join\n",
    "        print(\"Done.\")\n",
    "        return lcs\n",
    "    \n",
    "    def randSample(self, numLCs):\n",
    "        \"\"\"\n",
    "        Returns a random sample of numLCs light curves, data returned as an array\n",
    "        of shape [numLCs,3,len(t)]\n",
    "        Rerunning this, or randSampleWTabby will replace the previous random sample.\n",
    "        \"\"\"\n",
    "        self.numLCs = numLCs\n",
    "        print(\"Creating random file list...\")\n",
    "        self.dataSample = self.data.sample(n=numLCs)\n",
    "        self.filesSample = self.dataSample.index\n",
    "        print(\"Importing lightcurves...\")\n",
    "        self.lcs = self.poolRKC(self.filesSample)\n",
    "        return self.lcs\n",
    "    \n",
    "    def randSampleWTabby(self, numLCs):\n",
    "        \"\"\"\n",
    "        Returns a random sample of numLCs light curves, data returned as an array\n",
    "        of shape [numLCs,3,len(t)]\n",
    "        Rerunning this, or randSample will replace the previous random sample.\n",
    "        \"\"\"\n",
    "        self.numLCs = numLCs\n",
    "        print(\"Creating random file list...\")\n",
    "        self.dataSample = self.data.sample(n=numLCs)\n",
    "\n",
    "        print(\"Checking for Tabby...\")\n",
    "        if not dataSample.index.str.contains('8462852').all():\n",
    "            print(\"Adding Tabby...\")\n",
    "            self.dataSample.drop(self.dataSample.index[0])\n",
    "            self.dataSample.append(self.data[self.data.index.str.contains('8462852')])\n",
    "        self.filesSample = self.dataSample.index\n",
    "        print(\"Importing lightcurves...\")\n",
    "        self.lcs = self.poolRKC(self.filesSample)\n",
    "        return self.lcs\n",
    "    \n",
    "    def fullQ(self):\n",
    "        self.filesSample = self.files\n",
    "        self.dataSample = self.data\n",
    "        self.lcs = self.poolRKC(self.filesSample)\n",
    "        return self.lcs\n",
    "    \n",
    "    def tsne_fit(self,data):\n",
    "        \"\"\"\n",
    "        Performs a t-SNE dimensionality reduction on the data sample generated.\n",
    "        Uses a PCA initialization and the perplexity given, or defaults to 50.\n",
    "        \n",
    "        Appends the dataSample dataframe with the t-SNE X and Y coordinates\n",
    "        Returns tsneX and tsneY\n",
    "        \"\"\"\n",
    "        perplexity=50\n",
    "        scaler = preprocessing.StandardScaler().fit(data)\n",
    "        scaledData = scaler.transform(data)\n",
    "        tsne = TSNE(n_components=2,perplexity=perplexity,init='random',verbose=True)\n",
    "        tsne_fit=tsne.fit_transform(scaledData)\n",
    "        ### !!! CHANGE THIS BACK TO TSNE_FIT.T[0],TSNE_FIT.T[1] !!!\n",
    "        self.dataSample['tsne_x'] = tsne_fit.T[0]\n",
    "        self.dataSample['tsne_y'] = tsne_fit.T[1]\n",
    "        # Goal is to minimize the KL-Divergence\n",
    "        if sklearn.__version__ == '0.18.1':\n",
    "            print(\"KL-Divergence was %s\"%tsne.kl_divergence_ )\n",
    "        print(\"Done.\")\n",
    "        return tsne_fit.T[0],tsne_fit.T[1]\n",
    "    \n",
    "    def km_out(self):\n",
    "        tsneData = self.dataSample[['tsne_x','tsne_y']]\n",
    "        clusterLabels = km_outliers.kmeans_w_outliers(\n",
    "            self.filesSample,tsneData,1)\n",
    "        self.dataSample['km_cluster']=clusterLabels\n",
    "        \n",
    "    def db_out(self):\n",
    "        clusterLabels = db_outliers.dbscan_w_outliers(\n",
    "            self.dataSample[['tsne_x','tsne_y']])\n",
    "        self.dataSample['db_cluster']=clusterLabels\n",
    "        \n",
    "    def save(self,of):\n",
    "        data.to_csv(of)\n",
    "        \n",
    "sample = feature_importer(featCSV,fitsDir)\n",
    "randomSample = sample.randSample(102)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate random sampling of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tsnedata=sample.tsne_fit(sample.dataSample)\n",
    "except ValueError:\n",
    "    randomSample = sample.randSample(102)\n",
    "    print(\"retry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"K-means\")\n",
    "sample.km_out()\n",
    "print(\"DBSCAN\")\n",
    "sample.db_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply t-SNE dimensionallity reduction and plot for review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x=tsnedata[0]\n",
    "y=tsnedata[1]\n",
    "with sns.axes_style(\"darkgrid\"):\n",
    "    sns.kdeplot(x, y,shade=False,cmap=\"nipy_spectral\")\n",
    "    plt.scatter(x, y,alpha=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Run this before plotting in following cells.\"\"\"\n",
    "imported = True\n",
    "method = 'dbscan'\n",
    "\n",
    "def import_for_plot(df,method):\n",
    "    \"\"\"--- import light curve data ---\"\"\"\n",
    "    pathtofits = df.fitsDir\n",
    "\n",
    "    # The following needs to be generated in the cell above.\n",
    "    files = df.filesSample\n",
    "    if method == 'dbscan':\n",
    "        clusterLabels = df.dataSample.db_cluster\n",
    "    elif method == 'kmeans':\n",
    "        clusterLabels = df.dataSample.km_cluster\n",
    "    # data is an array containing each data point\n",
    "    data = np.array([np.array(df.dataSample[['tsne_x','tsne_y']].loc[i]) for i in df.dataSample.index])\n",
    "\n",
    "    cNorm  = colors.Normalize(vmin=0, vmax=max(clusterLabels))\n",
    "    scalarMap = cmx.ScalarMappable(norm=cNorm, cmap='jet')\n",
    "\n",
    "    # tsneX has all the x-coordinates\n",
    "    tsneX = data[:,0]\n",
    "    # tsneY has all the y-coordinates\n",
    "    tsneY = data[:,1]   \n",
    "    outX = []\n",
    "    outY = []\n",
    "    files_out = []\n",
    "    clusterX = []\n",
    "    clusterY = []\n",
    "    files_cluster = []\n",
    "\n",
    "    for i in enumerate(data):\n",
    "        if clusterLabels[i[0]] == -1:\n",
    "            outX.append(i[1][0])\n",
    "            outY.append(i[1][1])\n",
    "            files_out.append(files[i[0]])\n",
    "        else:\n",
    "            clusterX.append(i[1][0])\n",
    "            clusterY.append(i[1][1])\n",
    "            files_cluster.append(files[i[0]])\n",
    "\n",
    "    lightcurveData = sample.lcs\n",
    "\n",
    "    \"\"\"--- Organizing data and Labels ---\"\"\"\n",
    "    tabbyCheck = fnmatch.filter(files,'*8462852*')\n",
    "    if len(tabbyCheck)!=0:\n",
    "        tabbyInd = files.index(tabbyCheck[0])\n",
    "    else:\n",
    "        tabbyInd = 0\n",
    "    \n",
    "    return files,clusterLabels,data,\\\n",
    "cNorm,scalarMap,tsneX,tsneY,outX,\\\n",
    "outY,files_out,clusterX,clusterY,\\\n",
    "files_cluster,lightcurveData,tabbyInd\n",
    "\n",
    "\n",
    "files,clusterLabels,data,\\\n",
    "cNorm,scalarMap,tsneX,tsneY,outX,\\\n",
    "outY,files_out,clusterX,clusterY,\\\n",
    "files_cluster,lightcurveData,tabbyInd=import_for_plot(sample,method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot clusters (must be generated above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "\n",
    "root = Tk.Tk()\n",
    "root.wm_title(\"Scatter\")\n",
    "try:\n",
    "    test=imported\n",
    "    fig = Figure(figsize=(20,10))\n",
    "    \n",
    "    # a tk.DrawingArea\n",
    "    canvas = FigureCanvasTkAgg(fig, master=root)\n",
    "    canvas.get_tk_widget().pack(side=Tk.TOP, fill=Tk.BOTH, expand=1)\n",
    "    # Toolbar to help navigate the data (pan, zoom, save image, etc.)\n",
    "    toolbar = NavigationToolbar2TkAgg(canvas, root)\n",
    "    toolbar.update()\n",
    "    canvas._tkcanvas.pack(side=Tk.TOP, fill=Tk.BOTH, expand=1)\n",
    "    \n",
    "    gs = gridspec.GridSpec(2,6)\n",
    "    \n",
    "    with sns.axes_style(\"white\"):\n",
    "        # empty subplot for scattered data\n",
    "        ax = fig.add_subplot(gs[0,:4])\n",
    "        # empty subplot for lightcurves\n",
    "        ax2 = fig.add_subplot(gs[1,:])\n",
    "        # empty subplot for center detail\n",
    "        ax3 = fig.add_subplot(gs[0,4:])\n",
    "    \n",
    "    def distance(point, event):\n",
    "        \"\"\"Return distance between mouse position and given data point\n",
    "\n",
    "        Args:\n",
    "            point (np.array): np.array of shape (3,), with x,y,z in data coords\n",
    "            event (MouseEvent): mouse event (which contains mouse position in .x and .xdata)\n",
    "        Returns:\n",
    "            distance (np.float64): distance (in screen coords) between mouse pos and data point\n",
    "        \"\"\"\n",
    "        assert point.shape == (2,), \"distance: point.shape is wrong: %s, must be (2,)\" % point.shape\n",
    "        x2,y2 = ax.transData.transform((point[0],point[1]))\n",
    "\n",
    "        return np.sqrt ((x2 - event.x)**2 + (y2 - event.y)**2)\n",
    "    \n",
    "    def calcClosestDatapoint(XT, event):\n",
    "        \"\"\"Calculate which data point is closest to the mouse position.\n",
    "        \n",
    "        Args:\n",
    "            XT (np.array) - array of points, of shape (numPoints, 2)\n",
    "            event (MouseEvent) - mouse event (containing mouse position)\n",
    "        Returns:\n",
    "            smallestIndex (int) - the index (into the array of points X) of the element closest to the mouse position\n",
    "        \"\"\"\n",
    "        distances = [distance (XT[:,i], event) for i in range(XT.shape[1])]\n",
    "        \n",
    "        return np.argmin(distances)\n",
    "    \n",
    "    def drawData(X, index):\n",
    "        # Plots the lightcurve of the point chosen\n",
    "        ax2.cla()\n",
    "        \n",
    "        x=X[index][0]\n",
    "        y=X[index][1]\n",
    "        \n",
    "        axrange=0.55*(max(y)-min(y))\n",
    "        mid=(max(y)+min(y))/2\n",
    "        yaxmin = mid-axrange\n",
    "        yaxmax = mid+axrange\n",
    "        if yaxmin < .95:\n",
    "            if yaxmax > 1.05:\n",
    "                ax2.set_ylim(yaxmin,yaxmax)\n",
    "            else:\n",
    "                ax2.set_ylim(yaxmin,1.05)\n",
    "        elif yaxmax > 1.05:\n",
    "            ax2.set_ylim(.95,yaxmax)\n",
    "        else:\n",
    "            ax2.set_ylim(.95,1.05)\n",
    "\n",
    "        if files[index] in files_cluster:\n",
    "            color = 'blue'\n",
    "        else:\n",
    "            color = 'red'\n",
    "        ax2.plot(x, y, 'o',markeredgecolor='none', c=color, alpha=0.2)\n",
    "        ax2.plot(x, y, '-',markeredgecolor='none', c=color, alpha=0.7)\n",
    "        #ax2.set_title(files[index][:13],fontsize = 20)\n",
    "        ax2.set_xlabel('Time (Days)',fontsize=22)\n",
    "        ax2.set_ylabel(r'$\\frac{\\Delta F}{F}$',fontsize=30)\n",
    "        \n",
    "        fig.suptitle(files[index][:13],fontsize=30)\n",
    "        \n",
    "        canvas.draw()\n",
    "        \n",
    "    def annotatePt(XT, index):\n",
    "        \"\"\"Create popover label in 3d chart\n",
    "\n",
    "        Args:\n",
    "            X (np.array) - array of points, of shape (numPoints, 3)\n",
    "            index (int) - index (into points array X) of item which should be printed\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        x2, y2 = XT[index][0], XT[index][1]\n",
    "        # Either update the position, or create the annotation\n",
    "        if hasattr(annotatePt, 'label'):\n",
    "            annotatePt.label.remove()\n",
    "            annotatePt.emph.remove()\n",
    "        if hasattr(annotatePt, 'emphCD'):\n",
    "            annotatePt.emphCD.remove()\n",
    "\n",
    "        # Get data point from array of points X, at position index\n",
    "        annotatePt.label = ax.annotate( \"\",\n",
    "            xy = (x2, y2), xytext = (x2+10, y2+10),\n",
    "            arrowprops = dict(headlength=20,headwidth=20,width=6,shrink=.1,color='red'))\n",
    "        annotatePt.emph = ax.scatter(x2,y2,marker='o',s=50,c='red')\n",
    "        if files[index] in files_cluster:\n",
    "            annotatePt.emphCD = ax3.scatter(x2,y2,marker='o',s=150,c='red')\n",
    "        else:\n",
    "            annotatePt.emphCD = ax.scatter(x2,y2,marker='o',s=50,c='red')\n",
    "        canvas.draw()\n",
    "    \n",
    "    \n",
    "    def onMouseClick(event, X):\n",
    "        \"\"\"Event that is triggered when mouse is clicked. Shows lightcurve for data point closest to mouse.\"\"\"\n",
    "        XT = np.array(X.T) # array organized by feature, each in it's own array\n",
    "        closestIndex = calcClosestDatapoint(XT, event)\n",
    "        drawData(lightcurveData, closestIndex)\n",
    "        \n",
    "    def onMouseRelease(event, X):\n",
    "        XT = np.array(X.T)\n",
    "        closestIndex = calcClosestDatapoint(XT, event)\n",
    "        annotatePt(X,closestIndex)\n",
    "        #for centerIndex in centerIndices:\n",
    "        #    annotateCenter(XT,centerIndex)\n",
    "    \n",
    "    def connect(X):\n",
    "        if hasattr(connect,'cidpress'):\n",
    "            fig.canvas.mpl_disconnect(connect.cidpress)\n",
    "        if hasattr(connect,'cidrelease'):\n",
    "            fig.canvas.mpl_disconnect(connect.cidrelease)\n",
    "            \n",
    "        connect.cidpress = fig.canvas.mpl_connect('button_press_event', lambda event: onMouseClick(event,X))\n",
    "        connect.cidrelease = fig.canvas.mpl_connect('button_release_event', lambda event: onMouseRelease(event, X))\n",
    "    \n",
    "    def redraw():       \n",
    "        # Clear the existing plots\n",
    "        ax.cla()\n",
    "        ax2.cla()\n",
    "        ax3.cla()\n",
    "        # Set those labels\n",
    "        ax.set_xlabel(\"T-SNE X\",fontsize=18)\n",
    "        ax.set_ylabel(\"T-SNE Y\",fontsize=18)\n",
    "        # Scatter the data\n",
    "        ax.scatter(outX, outY,c=\"black\",s=30,cmap='jet')\n",
    "        ax.hexbin(clusterX,clusterY,mincnt=5,bins=\"log\",cmap=\"inferno\",gridsize=35)\n",
    "        \n",
    "        hb = ax3.hexbin(clusterX,clusterY,mincnt=5,bins=\"log\",cmap=\"inferno\",gridsize=35)\n",
    "        cb = fig.colorbar(hb)\n",
    "        ax3.set_title(\"Center Density Detail\")\n",
    "        ax3.set_xlabel(\"T-SNE X\",fontsize=18)\n",
    "        ax3.set_ylabel(\"T-SNE Y\",fontsize=18)\n",
    "        \n",
    "        \n",
    "        #for centerIndex in centerIndices:\n",
    "        #    annotateCenter(currentData1,centerIndex)\n",
    "        \n",
    "        if hasattr(redraw,'cidenter'):\n",
    "                fig.canvas.mpl_disconnect(redraw.cidenter)\n",
    "                fig.canvas.mpl_disconnect(redraw.cidexit)\n",
    "        connect(data)\n",
    "            \n",
    "        annotatePt(data,tabbyInd)\n",
    "        drawData(lightcurveData,tabbyInd)\n",
    "        #fig.savefig('Plots/Q16_PCA_kmeans/Tabby.png')\n",
    "        canvas.draw()\n",
    "        canvas.show()\n",
    "    print(\"Plotting.\")\n",
    "    \n",
    "    redraw() # First draw, Tabby plotted\n",
    "    \n",
    "    \n",
    "    def quit():\n",
    "        print(\"Exitting.\")\n",
    "        root.quit()\n",
    "        root.destroy()\n",
    "        \n",
    "    Tk.Button(root, text=\"Quit\", command=quit).pack()\n",
    "except NameError:\n",
    "    print(\"Run import cell above.\")\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "outX = []\n",
    "outY = []\n",
    "files_out = []\n",
    "clusterX = []\n",
    "clusterY = []\n",
    "files_cluster = []\n",
    "clusteredLabels = []\n",
    "\n",
    "for i in enumerate(data):\n",
    "    if clusterLabels[i[0]] == -1:\n",
    "        outX.append(i[1][0])\n",
    "        outY.append(i[1][1])\n",
    "        files_out.append(files[i[0]])\n",
    "    else:\n",
    "        clusterX.append(i[1][0])\n",
    "        clusterY.append(i[1][1])\n",
    "        files_cluster.append(files[i[0]])\n",
    "        clusteredLabels.append(clusterLabels[i[0]])\n",
    "        \n",
    "df = pd.DataFrame()\n",
    "df['t-SNE_X'] = clusterX\n",
    "df['t-SNE_Y'] = clusterY\n",
    "\n",
    "cNorm  = colors.Normalize(vmin=0, vmax=max(clusteredLabels))\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap='jet')\n",
    "           \n",
    "with sns.axes_style(\"white\"):\n",
    "\n",
    "    plt.xlabel(\"t-SNE X\",fontsize=18)\n",
    "    plt.ylabel(\"t-SNE Y\",fontsize=18)\n",
    "    #plt.hexbin(clusterX,clusterY,mincnt=1,bins=\"log\",cmap=\"inferno\",gridsize=35)\n",
    "    #plt.colorbar()\n",
    "    plt.scatter(clusterX,clusterY,marker='o',c=scalarMap.to_rgba(clusteredLabels))\n",
    "    plt.scatter(outX,outY,c=\"red\")\n",
    "    xmid = (max(clusterX)+min(clusterX))/2\n",
    "    xrng = (max(clusterX)-min(clusterX))/2\n",
    "    ymid = (max(clusterY)+min(clusterY))/2\n",
    "    yrng = (max(clusterY)-min(clusterY))/2\n",
    "    plt.scatter(data[tabbyInd][0],data[tabbyInd][1],c='green',s=50)\n",
    "    plt.xlim(xmid-xrng*1.05,xmid+xrng*1.05)\n",
    "    plt.ylim(ymid-yrng*1.05,ymid+yrng*1.05)\n",
    "    g = sns.jointplot(x=\"t-SNE_X\",y=\"t-SNE_Y\",data=df,kind='scatter',color=\"black\",stat_func=None,size=10,\\\n",
    "                      xlim=(xmid-xrng*1.05,xmid+xrng*1.05),ylim=(ymid-yrng*1.05,ymid+yrng*1.05),\\\n",
    "                      marginal_kws=dict(bins=200),\\\n",
    "                      joint_kws=dict(s=1))\n",
    "    \n",
    "    g.set_axis_labels(\"t-SNE X\",\"t-SNE Y\", fontsize=18)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
